\newcommand{\EncoderStatsTable}[6]{
  \begin{table}[!hbt]
  \noindent\makebox[\textwidth]{
  \footnotesize
  \centering
  \begin{tabu}{|c|r|X[r]|X[r]|X[r]|X[r]|X[r]|X[r]|}
    \tabucline{3-}
    \multicolumn{1}{c}{}
      & \multicolumn{1}{c|}{}
      & \multicolumn{2}{c|}{\textbf{btor2}}
      & \multicolumn{2}{c|}{\textbf{functional}}
      & \multicolumn{2}{c|}{\textbf{relational}} \\
    \tabucline{1-}
      \multicolumn{1}{|c|}{#2}
      & \multicolumn{1}{c|}{bound}
      & \multicolumn{1}{c|}{time}
      & \multicolumn{1}{c|}{size}
      & \multicolumn{1}{c|}{time}
      & \multicolumn{1}{c|}{size}
      & \multicolumn{1}{c|}{time}
      & \multicolumn{1}{c|}{size} \\
    \tabucline{1-}
    \firsthline
    \csvreader
      [late after line=\\] %, separator=pipe]
      {#1}
      {1=\A, 2=\B, 3=\C, 4=\D, 5=\E, 6=\F, 7=\G, 8=\H}
      {#3{\A} & \B & \C & \D & \E & \F & \G & \H}
    \lasthline
  \end{tabu}}
  \caption[#4]{#5}
  \label{#6}
  \end{table}
}

\newcommand{\CleanInf}[1]{\IfStrEq{#1}{inf}{-}{#1}}

\newcommand{\SolverStatsTable}[6]{
  \begin{table}[!hbt]
  \noindent\makebox[\textwidth]{
  \footnotesize
  \centering
  \begin{tabu}{|c|X[r]|X[r]|X[r]|X[r]|X[r]|X[r]|X[r]|}
    \tabucline{2-}
    \multicolumn{1}{c|}{}
      & \multicolumn{1}{c|}{\textbf{BtorMC}}
      & \multicolumn{2}{c|}{\textbf{Boolector}}
      & \multicolumn{2}{c|}{\textbf{Z3}}
      & \multicolumn{2}{c|}{\textbf{CVC4}} \\
    \tabucline{1-}
    \multicolumn{1}{|c|}{#2}
      & \multicolumn{1}{c|}{\scriptsize btor2}
      & \multicolumn{1}{c|}{\scriptsize functional}
      & \multicolumn{1}{c|}{\scriptsize relational}
      & \multicolumn{1}{c|}{\scriptsize functional}
      & \multicolumn{1}{c|}{\scriptsize relational}
      & \multicolumn{1}{c|}{\scriptsize functional}
      & \multicolumn{1}{c|}{\scriptsize relational} \\
    \tabucline{1-}
    \firsthline
    \csvreader
      [late after line=\\] %, separator=pipe]
      {#1}
      {1=\A, 2=\B, 3=\C, 4=\D, 5=\E, 6=\F, 7=\G, 8=\H}
      {#3{\A} & \CleanInf{\B} & \CleanInf{\C} & \CleanInf{\D} & \CleanInf{\E} & \CleanInf{\F} & \CleanInf{\G} & \CleanInf{\H}}
    \lasthline
  \end{tabu}}
  \caption[#4]{#5}
  \label{#6}
  \end{table}
}

\pgfplotsset{filter discard warning=false}
\tikzset{every mark/.append style={solid}}

\newcommand{\EncoderStatsGraph}[5]{
  \begin{figure}[!hbt]
    \footnotesize
    \centering
    \begin{tikzpicture}
      \pgfplotstableread[col sep=comma]{#1}{\Data}
      \begin{axis}[
        width=\textwidth,
        height=\axisdefaultheight + 16,
        % height=\axisdefaultheight, % - 60,
        grid=major,
        grid style={dashed,gray!30},
        % xlabel=X axis,
        % ylabel=Y axis,
        % ymode=log,
        % x tick label style={rotate=90,anchor=east},
        scaled ticks=false,
        x tick label style={anchor=north},
        y tick label style={/pgf/number format/.cd,fixed,1000 sep={\,}},
        xticklabels from table={\Data}{experiment},
        xtick=data,
        % filter discard warning=false,
        legend style={
          % draw=none,
          % at={(0.0,-0.1)},
          % anchor=north west,
          % at={(0.0,1.05)},
          % anchor=south west,
          font=\scriptsize,
          legend cell align=left,
          % legend pos=outer north east,
          legend pos=#2,
        },
      ]
      \addplot [black, mark=diamond*] table [x expr=\coordindex, y index=3] {\Data};
      \addlegendentry{\BTOR}
      \addplot [blue, mark=*] table [x expr=\coordindex, y index=5] {\Data};
      \addlegendentry{{\SMTLIB} (functional)}
      \addplot [red, mark=square*] table [x expr=\coordindex, y index=7] {\Data};
      \addlegendentry{{\SMTLIB} (relational)}
      \end{axis}
    \end{tikzpicture}
    \caption[#3]{#4}
    \label{#5}
  \end{figure}
}

\newcommand{\SolverStatsGraph}[5]{
  % https://texwelt.de/fragen/22222/pgfplots-x-achse-mit-strings
  \begin{figure}[!hbt]
    \small
    \centering
    \begin{tikzpicture}
      \pgfplotstableread[col sep=comma]{#1}{\Data}
      \begin{axis}[
        width=\textwidth,
        height=\axisdefaultheight + 16,
        grid=major,
        grid style={dashed,gray!30},
        % xlabel=X axis,
        % ylabel=Y axis,
        ymode=log,
        % x tick label style={rotate=90,anchor=east},
        x tick label style={anchor=north},
        xticklabels from table={\Data}{experiment},
        xtick=data,
        % filter discard warning=false,
        legend style={
          % draw=none,
          % at={(0.0,-0.1)},
          % anchor=north west,
          % at={(0.0,1.05)},
          % anchor=south west,
          font=\scriptsize,
          legend cell align=left,
          % legend pos=outer north east,
          legend pos=#2,
        },
      ]
      \addplot [black, mark=diamond*] table [x expr=\coordindex, y index=1] {\Data};
      \addlegendentry{BtorMC}
      \addplot [thick, dotted, blue, mark=*] table [x expr=\coordindex, y index=2] {\Data};
      \addlegendentry{Boolector (functional)}
      \addplot [thick, dotted, blue, mark=square*] table [x expr=\coordindex, y index=3] {\Data};
      \addlegendentry{Boolector (relational)}
      \addplot [dashed, red, mark=*] table [x expr=\coordindex, y index=4] {\Data};
      \addlegendentry{Z3 (functional)}
      \addplot [dashed, red, mark=square*] table [x expr=\coordindex, y index=5] {\Data};
      \addlegendentry{Z3 (relational)}
      \addplot [dashdotted, brown, mark=*] table [x expr=\coordindex, y index=6] {\Data};
      \addlegendentry{CVC4 (functional)}
      \addplot [dashdotted, brown, mark=square*] table [x expr=\coordindex, y index=7] {\Data};
      \addlegendentry{CVC4 (relational)}
      \end{axis}
    \end{tikzpicture}
    \caption[#3]{#4}
    \label{#5}
  \end{figure}
}

%------------------------------------------------------------------------------%

\section{Experiments}

To asses performance related aspects of our encodings,
we conducted a series of experiments, using the following versions of supported SMT solvers.
%a series of experiments have been conducted and
%
% show validity of Appendix \ref{appendix:litmus:intel}
% asses performance of our encodings by comparing the runtimes of all supported solvers
%
% Appendices \ref{appendix:litmus:intel} and \ref{appendix:litmus:amd}
%
% \todo[inline]{solver versions}
%
% \begin{table}[!hbt]
  % \centering
% \bigbreak
  % \begin{tabu}{lll}
    % % Solver & Version \\
    % % \hline
    % Boolector & 3.2.1 & \url{https://github.com/Boolector/boolector} \\
    % CVC 4 & 1.8 & \url{https://github.com/CVC4/CVC4} \\
    % Z3 & 4.8.9 & \url{https://github.com/Z3Prover/z3} \\
  % \end{tabu}
% % \bigbreak
% \end{table}
%
\begin{itemize}
  \item Boolector 3.2.1\footnote{\url{https://github.com/Boolector/boolector}} (including BtorMC)
  \item CVC4 1.8\footnote{\url{https://github.com/CVC4/CVC4}}
  \item Z3 4.8.9\footnote{\url{https://github.com/Z3Prover/z3}}
\end{itemize}
%
% Intel(R) Xeon(R) E5-2620 v4 @ 2.10GHz
% All tests were performed on a cluster of Intel\textsuperscript{\textregistered} Xeon\textsuperscript{\textregistered} E5-2620 v4 nodes, where runtime and memory usage were limited to 86400 seconds (24 hours) and 8 GB respectively.

We recorded the resulting formula sizes in terms of the number of generated expression, as well as the runtimes for encoding and solving each particular instance.
All tests were performed on a cluster of Intel\textsuperscript{\textregistered} Xeon\textsuperscript{\textregistered} E5-2620 v4 nodes, with CPU runtime and memory usage limited to 86400 seconds (24 hours) and 8 GB respectively.

% The x86-TSO memory ordering model (used by AMD and Intel) is defined by a set of litmus tests.
% To show equivalence of ConcuBinE-TSO and x86-TSO, the tests have been ported to ConcuBinE.

\subsection*{Litmus Tests}

Instead of a rigorous formal description, the memory ordering principles of Intel's \cite{ref:Intel} and AMD's \cite{ref:AMD} x86 implementations are defined by example through a set of \CHANGE{so called ``litmus tests''}.
% In order to show their conformance with the memory ordering model of our virtual machine, all documented litmus tests have been ported to ConcuBinE and are explained in Appendices \ref{appendix:litmus:intel} and \ref{appendix:litmus:amd}.
In order to show conformance with the memory ordering model of our virtual machine, the test suites have been ported to ConcuBinE and \CHANGE{details are available} in Appendices \ref{appendix:litmus:intel} and \ref{appendix:litmus:amd}.

% Encoder statistics are shown in Table \ref{tbl:litmus:intel:encoder} and formula sizes visualized in Figure \ref{fig:litmus:intel:encoder}.

% amd 1 = intel 1
% amd 2 = intel 2
% amd 4 = intel 3 - shows same behaviour as amd 3
% amd 6 = intel 7
% amd 8 = intel 5

% \subsubsection*{Intel}
% \newcommand{\StatsTableRowHeader}[1]{\StrBehind[2]{#1}{:}}
% \newcommand{\StatsTableRowHeader}[1]{\ref{tbl:#1}}
% \newcommand{\StatsTableRowHeader}[1]{\hyperref[tbl:#1]{\StrBehind[2]{#1}{:}}}
\newcommand{\IntelRowHeader}[1]{\hyperref[tbl:litmus:intel:#1]{#1}}
\newcommand{\AMDRowHeader}[1]{\hyperref[tbl:litmus:amd:#1]{#1}}

% \todo[inline]{table - encoding stats - litmus intel}
\EncoderStatsTable
  {figures/litmus-intel-encoder.csv}
  {\textnumero}
  {\IntelRowHeader}
  {Intel litmus test encoder statistics.}
  {Intel litmus test encoding times in milliseconds and formula sizes \CHANGE{in terms of} the number of expressions.}
  {tbl:litmus:intel:encoder}
  % {Intel Litmus Test Econding Time [ms] and Size [\#expressions]}

% \vspace{3cm}

Bounds and encoder statistics of both test suites are given in Tables \ref{tbl:litmus:intel:encoder} and \ref{tbl:litmus:amd:encoder}.
Comparing the sizes of generated formulas, visualized in Figures \ref{fig:litmus:intel:encoder} and \ref{fig:litmus:amd:encoder}, clearly shows the main advantage \CHANGE{of} using {\BTOR}:
compact problem instances and reduced computational complexity of it's encoding process
% it's compactness and reduced computational complexity of it's encoding process
due to being automatically unrolled for any given bound via symbolic substitution by BtorMC at runtime.
Furthermore, the additional redundancy introduced by the relational next state logic causes a quite substantial gap between the size of our {\SMTLIB} encoding variants.

% being automatically unrolled by passing the required bound to BtorMC, and reducing computational complexity of it's encoding process.
% While our {\SMTLIB} encodings are explicitly unrolled for each specific bound, {\BTOR}'s sequential extension being unroll

\EncoderStatsGraph
  {figures/litmus-intel-encoder.csv}
  {north west}
  {Intel litmus test encoder graph.}
  {Intel litmus test formula sizes \CHANGE{in terms of} the number of expressions.}
  {fig:litmus:intel:encoder}

\EncoderStatsTable
  {figures/litmus-amd-encoder.csv}
  {\textnumero}
  {\AMDRowHeader}
  {AMD litmus test encoder statistics.}
  {AMD litmus test encoding times in milliseconds and formula sizes \CHANGE{in terms of} the number of expressions.}
  {tbl:litmus:amd:encoder}
  % {AMD Litmus Test Econding Time [ms] and Size [\#expressions]}

% \vspace{3cm}

\EncoderStatsGraph
  {figures/litmus-amd-encoder.csv}
  {north west}
  {AMD litmus test encoder graph.}
  {AMD litmus test formula sizes \CHANGE{in terms of} the number of expressions.}
  {fig:litmus:amd:encoder}

% Table \ref{tbl:litmus:intel:encoder} shows the runtimes and formula sizes for encoding Intel's litmus test suite.
% Encoder statistics are shown in Table \ref{tbl:litmus:intel:encoder} and formula sizes visualized in Figure \ref{fig:litmus:intel:encoder}.

% Table \ref{tbl:litmus:intel:encoder} shows bounds and encoder statistics for Intel's litmus test suite, with formula sizes plotted in Figure \ref{fig:litmus:intel:encoder} for better visual comparison.
% It highlights one of the main advantages of using the {\BTOR} format.
% \newpage
% Solving times are listed in Table \ref{tbl:litmus:intel:solver} and visualized in Figure \ref{fig:litmus:intel:solver}.

% \todo[inline]{table - solving times - litmus intel}

\newpage

\hyphenation{MiniSAT}

% Our virtual machine model passed all litmus tests, with solving times given in Tables \ref{tbl:litmus:intel:solver} and \ref{tbl:litmus:amd:solver}.
All litmus tests passed and the claim, that the encodings of our virtual machine model conform with the memory ordering principles of both major x86 vendors therefore validated by example.
% is therefore validated.
The corresponding solving times, given in Tables \ref{tbl:litmus:intel:solver} and \ref{tbl:litmus:amd:solver}, reveal a dramatic difference
% in the effectiveness
between the tested solvers and encoding variants,
even forcing us to resort to
a logarithmic scale for plotting runtimes \CHANGE{as} shown in Figures \ref{fig:litmus:intel:solver} and \ref{fig:litmus:amd:solver} to get a meaningful graphical representation.
% BtorMC and Boolector turned out to be the fastest, with little difference between the functional {\BTOR} and {\SMTLIB} encodings.
Our functional encoding ({\BTOR} and {\SMTLIB}) turned out to be the fastest, with BtorMC on top, closely followed by Boolector and Z3.
As expected, the relational {\SMTLIB} approach is somewhat slower, but still beats CVC4 for any encoding variant when using Boolector or Z3.
% Talking to two CVC4 developers uses a customized version of MiniSAT\footnote{\url{http://minisat.se}} as SAT backend for \texttt{QF_AUFBV} theory combination
% Talking to two CVC4 developers revealed
\CHANGE{After reporting this observation to members of CVC4's development team it was confirmed}
that the latest release still uses a customized version of MiniSAT\footnote{\url{https://github.com/niklasso/minisat}} %http://minisat.se}}
as SAT backend for \texttt{QF_AUFBV} formulas, which seems to be the main reason
for the performance gap
% for performing poorly
in comparison to Boolector (incorporating CaDiCaL\footnote{\url{https://github.com/arminbiere/cadical}} 1.0.3) and Z3.

\newpage

\SolverStatsTable
  {figures/litmus-intel-solver.csv}
  {\textnumero}
  {\IntelRowHeader}
  {Intel litmus test solver statistics.}
  {Intel litmus test solving times in seconds.}
  {tbl:litmus:intel:solver}
  % {Intel Litmus Test Solving Times in Seconds}

\SolverStatsGraph
  {figures/litmus-intel-solver.csv}
  {north west}
  {Intel litmus test solver graph.}
  {Intel litmus test solving times in seconds.}
  {fig:litmus:intel:solver}

\newpage

% \subsubsection*{AMD}

% \todo[inline]{table - encoding stats - litmus amd}
% \renewcommand{\StatsTableRowHeader}[1]{\hyperref[tbl:litmus:amd:#1]{#1}}

% \newpage
% \todo[inline]{table - solving times - amd}

\SolverStatsTable
  {figures/litmus-amd-solver.csv}
  {\textnumero}
  {\AMDRowHeader}
  {AMD litmus test solver statistics.}
  {AMD litmus test solving times in seconds.}
  {tbl:litmus:amd:solver}
  % {AMD Litmus Test Solving Times in Seconds}

\SolverStatsGraph
  {figures/litmus-amd-solver.csv}
  {north west}
  {AMD litmus test solver graph.}
  {AMD litmus test solving times in seconds.}
  {fig:litmus:amd:solver}

\newpage

\subsection*{Concurrent Counter}

% https://tex.stackexchange.com/questions/141892/how-can-i-put-a-curly-brace-inside-a-listing-to-group-code-lines
\newcommand{\tikzmark}[1]{\tikz[overlay,remember picture] \node (#1) {};}
\newcommand*{\AddNote}[3]{%
  \begin{tikzpicture}[overlay, remember picture]
    \draw [decoration={brace,amplitude=0.5em},decorate,thick,red!60!black]
      ($(#1)!([yshift=1.5ex]#1)!($(#1)-(0,1)$)$) --
      ($(#1)!(#2)!($(#1)-(0,1)$)$)
      node [align=center, text width=1.0cm, pos=0.5, anchor=west] {\textsf{#3}};
  \end{tikzpicture}
}%

% In order to show the effective scalability of our approach,
% a parametrizable version of Paul McKenney's statistical counter \cite{ref:McKenney17},
% $n$ threads concurrently incrementing a global counter $m$ times.

To show the scalability of our approach, we \CHANGE{also} use a \CHANGE{parametrized} concurrent counter \CHANGE{(inspired by Paul McKenney \cite{ref:McKenney17})}, where $m$ threads increment a shared variable $n$ times.
Two flavours were tested: a \CHANGE{faulty} version using \lstinline[style=asm]{STORE} to compare runtimes of satisfiable instances and a \CHANGE{valid} one relying on \lstinline[style=asm]{CAS}, resulting in unsatisfiable runs.
% Any combination of $2 \leq m \leq 4$ threads and $2 \leq n \leq 4$ local increments were considered.
% Any combination of $2 \leq m \leq 4$ threads, each incrementing the shared counter $2 \leq n \leq 4$ times were considered.
% We considered any combination of $2 \leq m \leq 4$ threads and $2 \leq n \leq 4$ local increments.
% We considered any combination of $2 \leq m \leq 4$ threads, each incrementing the global count $2 \leq n \leq 4$ times.
% We chose a set of parameter configurations large enough to give representative results while still being solvable within the given time and memory limits and both
Both were executed for any combination of $2 \leq m \leq 4$ threads and $2 \leq n \leq 4$ increments respectively,
\CHANGE{forming a set of parameter configurations large enough to yield representative results while still being solvable within the given time and memory limits.}
% \CHANGE{for a set of parameter configurations large enough to show progressive hardness while still being solvable within the given time and memory limits$^?$}.

% \subsubsection*{Buggy}
% \noindent
% \begin{minipage}[b]{0.5\textwidth}
% \vspace{0pt}
% \begin{lstlisting}[style=asm, caption={Buggy counter template.}, label={lst:count:buggy}, mathescape, xleftmargin=0.39\textwidth]
\begin{lstlisting}[style=asm, caption={\CHANGE{Faulty} counter template.}, label={lst:count:buggy}, xleftmargin=0.39\textwidth]
inc: LOAD 0  `\tikzmark{inc-start}`
ADDI 1
STORE 0
LOAD <adr>
SUBI 1
STORE <adr>
JNZ inc      `\tikzmark{inc-end}`
CHECK 0      `\AddNote{inc-start}{inc-end}{inc}`
HALT
\end{lstlisting}
% \end{minipage}
% \hfill
% \begin{minipage}[b]{0.49\textwidth}
% \vspace{0pt}
% \hfill
% \begin{lstlisting}[style=asm, caption={Checker template.}, label={lst:count:checker}, mathescape, xleftmargin=0.29\textwidth]
% CHECK 0
% ADDI <sum>
% CMP 0
% JNZ error
% EXIT 0
% error: EXIT 1
% \end{lstlisting}
% \end{minipage}

\vspace{-.1\baselineskip}

Listing \ref{lst:count:buggy} shows the \CHANGE{faulty} counter template. % , where the local counter's address \texttt{<adr>} is replaced by $t + 1$ for every thread $0 \leq t < m$.
Each thread $t$ starts by loading, incrementing and storing the shared counter at address 0.
Next, the local counter (limiting the number of iterations) is loaded, decremented and simply stored at the address specified by the template parameter \texttt{<adr>}, which is replaced by $t + 10$ for each thread $0 \leq t < m$.
% which is initialized
% , which is replaced by $t + 1$ for each thread $0 \leq t < m$ and initialized with the specific number of iterations $n$.
% If this local counter is greater than zero, the process is restarted by jumping back to the initial instruction. % labelled \texttt{inc}.
If this local counter (initialized with $n$) remains greater than zero, the counting process is restarted by jumping back to the initial program statement.
% The process is restarted by jumping back to the initial program statement if this local counter, initialized with $n$, remains greater than zero.
% Otherwise, the threads synchronize upon checkpoint 0, signaling that counting has finished and the checker thread given in Listing \ref{lst:count:checker} should start evaluating the result.
Otherwise, the threads synchronize upon checkpoint 0, signaling that counting has finished and the result should be evaluated.
% by comparing it to the expected value $m * n$, being supplied by yet another template parameter \texttt{<sum>}.
The checker thread given in Listing \ref{lst:count:checker} then compares the shared counter at address 0 to the expected value $m * n$ supplied by yet another template parameter \texttt{<sum>} and exits 1 if they differed.
% \begin{minipage}[t]{0.45\textwidth}
% \vspace{0pt}
\begin{lstlisting}[style=asm, caption={Checker template.}, label={lst:count:checker}, mathescape, xleftmargin=0.39\textwidth]
CHECK 0
ADDI <sum>
CMP 0
JNZ error
EXIT 0
error: EXIT 1
\end{lstlisting}
% \end{minipage}
% \pagebreak
% The checker routine uses another template parameter \texttt{<sum>}
% We use another template parameter \texttt{<sum>} being substituted with the expected value $m * n$
% The checker thread then compares the shared counter to the expected value $\texttt{<sum>} = m * n$.
% and instructions the machine to exit 1 by jumping to the corresponding exit statement if they differ.
% Validation is done by simply subtracting the shared counter at address 0 from it's expected value $m * n$, being supplied by yet another template parameter \texttt{<sum>}.
% If they differ and the checker thread's accumulator register is non-zero, then we jump to the corresponding exit

In this example, relying on \lstinline[style=asm]{STORE} to write a shared variable leads to an obvious data-race, even without the additional inconsistency introduced by the store buffer.
Since an exit code greater than zero will serve as the bad state in the resulting model checking problem, we now must choose a proper bound
% for every possible combination of $m$ and $n$
such that the program will be fully executed
% Finally, we must choose the proper bound, such that the program will be fully executed
and the checker thread's exit statements can be reached.
% Else, the formula won't be satisfiable, since we check for an exit code greater than zero as the bad state in our model checking problem.
% and the formula is not unsatisfiable due to not being able to reach the
% Therefore, we have to find the length of the longest possible trace,
% This translates to finding the worst-case execution time in the number of steps
% We therefore have to find the worst-case execution time in the number of steps, translating to the longest possible trace through the program.
We therefore have to find the longest possible trace through the program, it's worst-case execution time so to say.
% For our buggy counter, the process is straight forward and can simply be determined by the number of steps required by each iteration of the counting loop \textsf{inc} (7 instructions + 2 flushes), adding the 2 instructions to reach the counting program's end and multiply the result by the number of participating threads.
% TODO
For our \CHANGE{faulty} counter, the process is \CHANGE{straightforward} and it can simply be determined by adding $n$ times the number of steps required by each iteration of the counting loop {\color{red!60!black}\textsf{inc}} (7 instructions + 2 flushes) to the 2 instructions left for completing the counter thread's execution.
% All that's missing to get the bound is adding the 5 steps required by the checker thread and can be summarized using the following equation.
The minimum required bound can now be computed by multiplying the result with the number of participating threads $m$ and adding the 5 steps needed by the checker thread, leading to the following equation.
% To get the bound, we multiply the result by the number of participating threads $m
% In order to ensure
% \[
  % m * (11 + 9 * (n - 1)) + 5
% \]
\[
  m * (9 * n + 2) + 5
\]
% For example, in case of $m = n = 2$, requires a bound of
% In case of $m = n = 2$ for example, a minimum bound of
% $
  % 2 * (2 * 9 + 2) + 5 = 45
% $ is required.
For example, $m = n = 2$ would require a bound of $2 * (9 * 2 + 2) + 5 = 45$.
% For example, in case of $m = n = 2$, a bound greater or equal than $2 * (2 * 9 + 2) + 5 = 45$ would be required.

% In order to correct behaviour, we must ensure that the checker thread
% In terms of our buggy counter, the minimum bound required to fully execute the experiment using $m$ threads, we just need to determine the number of steps to complete

% \bigbreak
% \todo[inline]{bound}

% \renewcommand{\StatsTableRowHeader}[1]{%
% \StrBehind{#1}{:}[\SplitColon]%
% \StrBehind{\SplitColon}{.}[\SplitDot]%
% \StrSubstitute{\SplitDot}{.}{ }%
% }
% \renewcommand{\StatsTableRowHeader}[1]{#1}
% \newcommand{\CountRowHeader}[1]{\StrSubstitute{#1}{ }{$\;$}}
\newcommand{\CountRowHeader}[1]{\StrSubstitute{#1}{ }{\hfill}}

% \todo[inline]{table - encoding stats - count buggy}

\bigbreak

\EncoderStatsTable
  {figures/count-buggy-encoder.csv}
  {m n}
  {\CountRowHeader}
  {\CHANGE{Faulty} counter encoder statistics.}
  {\CHANGE{Faulty} counter encoding times in milliseconds and formula sizes \CHANGE{in terms of} the number of expressions for increasing values of $m$ and $n$.}
  {tbl:count:buggy:encoder}

Table \ref{tbl:count:buggy:encoder} shows the bounds and encoder statistics of our \CHANGE{faulty} counter experiments.
While encoder runtimes are rather negligible, Figure \ref{fig:count:buggy:encoder} again highlights the dramatic difference in size between {\BTOR} and {\SMTLIB} encoding variants for increasing values of $m$ and $n$. %, with the required bound being the main driving factor. % for the generated formula's size.
% The formula sizes, visualized in Figure \ref{fig:count:buggy:encoder}
% While the size of both {\SMTLIB} encodings increases linearly for fixed values of $m$ or $n$. % the {\BTOR} variant  independece from $n$
% \todo[inline]{mention {\BTOR's} independece from $n$}
% With the relational additionally suffering from the redundancy introduced by a growing number of threads.
As expected, the number of participating threads $m$ is the main driving factor for
% increasing the required bound and resulting formula's size (compare $m = 2$, $n = 2$ to $m = 4$, $n = 2$).
% an increased problem size
% increasing the resulting problem's size.
increasing the problem size.
% (compare $(m, n) \in \{(2, 2), (2, 4), (4, 2), (4, 4)\}$).
% (compare $m = 2$, $n = 2$ to $m = 4$, $n = 2$ and $m = 2$, $n = 2$ to $m = 2$, $n = 4$).
% Especially noticeable for {\SMTLIB} variants
% (compare $(m, n) = (2, 2)$ to $(4, 2)$ and $(2, 2)$ to $(2, 4)$).
% (compare 2 2 to 4 2 and 2 2 to 2 4).
% The off-by-one differences in the size of the {\BTOR} encodings for an equal number of threads can be explained by the definition of constants required by the local counter addresses and the expected result.
The off-by-one differences in the size of the {\BTOR} encodings for an equal number of threads $m$ can be explained by the reuse of constants necessary to specify local counter addresses and the expected final value.

\newpage

\EncoderStatsGraph
  {figures/count-buggy-encoder.csv}
  {north west}
  {\CHANGE{Faulty} counter encoder graph.}
  {\CHANGE{Faulty} counter formula sizes \CHANGE{in terms of} the number of expressions for increasing values of $m$ and $n$.}
  {fig:count:buggy:encoder}

% Table \ref{tbl:count:buggy:solver} shows the runtime required to find a model to the specific problem and are visualized in Figure \ref{fig:count:buggy:solver}.
% Table \ref{tbl:count:buggy:solver} shows the time it took any of the supported solvers to find an erroneous trace, which again required the use of a logarithmic scale for getting a meaningful visual representation in Figure \ref{fig:count:buggy:solver}.
The time it took the supported solvers to find faulty traces for our \CHANGE{faulty} counter experiments are listed in Table \ref{tbl:count:buggy:solver} and visualized in Figure \ref{fig:count:buggy:solver}.
Only BtorMC, Boolector using the functional and Z3 using the relational next state logic were able to find a solution for all experiments.
% BtorMC and Boolector turned out to be on top with little difference between the two.
Surprisingly, Z3 in combination with the functional next state logic performed much worse than expected and was just able to solve as many instances as Boolector using the relational variant.
CVC4 however could not even solve a single instance within the given time and memory limits, \CHANGE{again most likely due to the SAT solver used}.

\bigbreak

\SolverStatsTable
  {figures/count-buggy-solver.csv}
  {m n}
  {\CountRowHeader}
  {\CHANGE{Faulty} counter solver statistics.}
  {\CHANGE{Faulty} counter solving times in seconds for increasing values of $m$ and $n$.}
  {tbl:count:buggy:solver}

\newpage

\SolverStatsGraph
  {figures/count-buggy-solver.csv}
  {south east}
  {\CHANGE{Faulty} counter solver graph.}
  {\CHANGE{Faulty} counter solving times in seconds for increasing values of $m$ and $n$.}
  {fig:count:buggy:solver}

% \subsubsection*{CAS}

% Finally, we also experimented with a consistent version of the previous concurrent counter example to evaluate the solvers behaviour on unsatisfiable instances. % of our proposed encoding.
% Listing \ref{lst:count:cas} shows the updated counter thread, now resorting to \emph{compare and swap} for writing the shared counter variable.
% After loading and memorizing the current counter value with \lstinline[style=asm]{MEM},
Finally, we also experimented with a \CHANGE{valid} version of the previous concurrent counter example, given in Listing \ref{lst:count:cas}, which resorts to \CHANGE{\emph{compare-and-swap}} for writing \CHANGE{a} shared variable in a predictable manner.
% Finally, we also experimented with a consistent version of the previous concurrent counter example, which is given in Listing \ref{lst:count:cas} and resorts to \emph{compare and swap} for writing the shared variable in a predictable manner.
% After reading and memorizing the counter's current value for a latter application of \lstinline[style=asm]{CAS} using \lstinline[style=asm]{MEM},
Instead of simply reading the shared counter's value, we now use \lstinline[style=asm]{MEM} to additionally memorize it for the latter application of \lstinline[style=asm]{CAS}.
% The initial \lstinline[style=asm]{LOAD 0}, responsible for reading the shared counter, is replaced by \lstinline[style=asm]{MEM 0} to additionally memorize it for the latter application of \lstinline[style=asm]{CAS}.
% Since \lstinline[style=asm]{CAS} might fail due to an intermediate alteration of the shared counter variable by another thread, it must be embedded in a nested loop {\color{red!60!black}\textsf{cas}}, repeating the increment until it succeeds to prevent an erroneous decrement of the thread's local counter variable and ensure consistency.
% to prevent a subsequent decrement of the thread's local counter by repeating the increment until it succeeds.
Since \lstinline[style=asm]{CAS} might fail due to an intermediate alteration of the shared counter variable by another thread, we must prevent an erroneous subsequent decrement of the thread's local counter variable by embedding it in a nested loop (\CHANGE{labelled} {\color{red!60!black}\textsf{cas}})
and repeat the increment until it succeeds. % to ensure consistency.
% , repeating the increment until it succeeds. % to ensure consistency.
% The rest of the counter program remains the same and
Everything else remains the same, including the checker thread.

\vfill

% \begin{lstlisting}[style=asm,caption={Consistent counter template, using {\lstinline[style=asm]{CAS}}.},mathescape,xleftmargin=0.39\textwidth]
\begin{minipage}{\textwidth}
\begin{lstlisting}[style=asm, caption={\CHANGE{Valid} counter template.}, label={lst:count:cas}, xleftmargin=0.39\textwidth]
inc: MEM 0  `\tikzmark{cas-start}`      `\tikzmark{inc-start}`
ADDI 1
CAS 0
JZ inc      `\tikzmark{cas-end}`
LOAD <adr>
SUBI 1
STORE <adr>
JNZ inc                                 `\tikzmark{inc-end}`
CHECK 0
HALT
\end{lstlisting}
\AddNote{cas-start}{cas-end}{cas}
\AddNote{inc-start}{inc-end}{inc}
\end{minipage}

% Determining the required bound is a bit more complex, since we also have to account for the theoretically possible maximum number of failed \lstinline[style=asm]{CAS} instructions.
Determining the required bound is a bit more complex, since we also have to account for the maximum number of failed \lstinline[style=asm]{CAS} instructions to ensure that all possible traces are included in the search space.
% There may exist a trace in which the participating counter threads are scheduled one after the other,
This worst case can occur if the participating counter threads are scheduled one after the other,
% \[
  % t_0 \rightarrow^0 t_1 \rightarrow \ldots \rightarrow t_{m - 2} \rightarrow t_{m - 1} \rightarrow t_0 \rightarrow t_1 \rightarrow \ldots \rightarrow t_{m - 2} \rightarrow t_{m - 1}
% \]
\[
  \THREAD^0_0 \rightarrow \ldots \rightarrow \THREAD^{m - 1}_{m - 1} \rightarrow \THREAD^m_0 \rightarrow \ldots \rightarrow \THREAD^{2m - 1}_{m - 1} \rightarrow \ldots
\]
causing all but one (the first) to fail in each iteration of the counting loop {\color{red!60!black}\textsf{inc}}.
Consider the following example trace
% of \lstinline[style=asm]{CAS} instructions
for $m = 2$ and $n = 1$,
% where $i_t$ denotes the local counter of thread $t$.
where counting to $m * n = 2$ may require up to
three {\color{red!60!black}\textsf{cas}} loop iterations in total.
% the execution of up to three \lstinline[style=asm]{CAS} instructions.
% \begin{table}[!hbt]
  % \centering
\begin{center}
  \begin{tabu}{lll}
    % \firsthline
    Thread & \lstinline[style=asm]{CAS} Status & Local Counter \\
    % \hlIne
    \hline
    0 & done & 0 \\
    1 & failed & 1 \\
    % $\ldots$ & & \\
    \hline
    \hline
    1 & done & 0 \\
    \lasthline
  \end{tabu}
\end{center}
% \end{table}
If we now examine the influence by an increased number of threads ($m = 3$ and $n = 1$),
% the maximum number of executed \lstinline[style=asm]{CAS} instructions increases to six.
% already six {\color{red!60!black}\textsf{cas}} iterations are required in this scenario.
one notices that the maximum number of {\color{red!60!black}\textsf{cas}} iterations follows a \emph{triangular number}: $m * \frac{m + 1}{2} = 6$.
% \begin{table}[!hbt]
  % \centering
\begin{center}
  \begin{tabu}{lll}
    Thread & \lstinline[style=asm]{CAS} Status & Local Counter \\
    \hline
    0 & done & 0 \\
    1 & failed & 1 \\
    2 & failed & 1 \\
    % $\ldots$ & & \\
    \hline
    \hline
    1 & done & 1 \\
    2 & failed & 0 \\
    % $\ldots$ & & \\
    \hline
    \hline
    2 & done & 1 \\
    \lasthline
  \end{tabu}
\end{center}
% \end{table}
% Counting to three may require the execution of up to six \lstinline[style=asm]{CAS} instructions.
Since increasing the local increments $n$ \CHANGE{directly influences} the number of {\color{red!60!black}\textsf{cas}} iterations, we just need to multiply the previously identified \emph{triangular number} by $n$ to get the maximum: $n * m * \frac{m + 1}{2}$.
% Now, if we add the number of steps required by each iteration of the {\color{red!60!black}\textsf{cas}} loop to $n$ times
% Now, if we multiply this number with the length of the
% If we now consider the number of steps required by each iteration of the {\color{red!60!black}\textsf{cas}} loop (4), the ones left to complete the counting loop {\color{red!60!black}\textsf{inc}} (5) and the remaining 2 instructions to complete the counter thread's execution, as well as the checker thread (5), the final bound can be computed by the following expression.
If we now consider the number of steps required by each iteration of the {\color{red!60!black}\textsf{cas}} loop (4), the ones left to complete the counting loop {\color{red!60!black}\textsf{inc}} (5) and the 2 instructions remaining in the counter thread's program, % as well as the checker thread (5),
the final bound can be computed by the following equation.
\[
  m * (4 * n * m * \frac{m + 1}{2} + 5 * n + 2) + 5
\]
% For example, $m = n = 2$ would in this case already require a bound of $(4 * 2 * 2 * \frac{2 + 1}{2} + 5 * 2 + 2) * 2 + 5 = 77$.
For example, the \CHANGE{valid} counter experiment for $m = n = 2$ already requires a bound of $(4 * 2 * 2 * \frac{2 + 1}{2} + 5 * 2 + 2) * 2 + 5 = 77$.

\newpage

Bounds and encoder statistics for our \CHANGE{valid} counter experiments are given in Table \ref{tbl:count:cas:encoder} and formula sizes visualized in Figure \ref{fig:count:cas:encoder}.
% Again, the sizes of {\BTOR} formulas are just a fraction of
% The formula sizes of our {\SMTLIB} variants, visualized in Figure \ref{fig:count:cas:encoder},
% Even though the consistent version just adds a single instruction to the counter thread's program, the larger bound required by the nested loop causes a quite large blowup in the resulting formulas sizes of {\SMTLIB} variants.
% While the formula sizes of our {\BTOR} encoding are slightly increased due to the
% While the addition of a single instruction slightly increases the formula sizes of our {\BTOR} encoding, the larger bound required by the introduction of a nested loop causes a significant blowup in terms of our {\SMTLIB} variants.
While the addition of a single instruction only slightly increases the formula sizes of our {\BTOR} encoding, the {\SMTLIB} variants exhibit a significant blowup due to the larger bound required by the introduction of a nested loop.
Naturally, encoder runtimes are also affected, but remain acceptable as all experiments could be encoded in less than a second.

\bigbreak

\EncoderStatsTable
  {figures/count-cas-encoder.csv}
  {m n}
  {\CountRowHeader}
  {\CHANGE{Valid} counter encoder statistics.}
  {\CHANGE{Valid} counter encoding times in milliseconds and formula sizes \CHANGE{in terms of} the number of expressions for increasing values of $m$ and $n$.}
  {tbl:count:cas:encoder}

\EncoderStatsGraph
  {figures/count-cas-encoder.csv}
  {north west}
  {\CHANGE{Valid} counter encoder graph.}
  {\CHANGE{Valid} counter formula sizes \CHANGE{in terms of} the number of expressions for increasing values of $m$ and $n$.}
  {fig:count:cas:encoder}

\newpage

Solving times of this experiment's unsatisfiable runs are shown in Table \ref{tbl:count:cas:solver} and visualized in Figure \ref{fig:count:cas:solver}.
% 7 out of 63
Unfortunately, only 3 out of 9 experiments could be solved by BtorMC and Boolector within the given time and memory limits.
This puts the practicability of our approach in question, since further increasing the program size, number of threads and bound required by even the tiniest real world example
would generate problem instances which most \CHANGE{likely} won't be solvable in a reasonable amount of time,
% won't be solvable in a reasonable amount of time
% and maybe even surpass the user's life expectancy.
% A verification routine that possibly requires more time to complete than it's user's life expectancy surely won't increase software quality, not even in the long run.
\CHANGE{possibly due to symmetric execution parts.}
\CHANGE{Thus, these examples probably meet some kind of symmetry reduction or use a form of partial order reduction.}

\vfill

\SolverStatsTable
  {figures/count-cas-solver.csv}
  {m n}
  {\CountRowHeader}
  {\CHANGE{Valid} counter solver statistics.}
  {\CHANGE{Valid} counter solving times in seconds for increasing values of $m$ and $n$.}
  {tbl:count:cas:solver}

\SolverStatsGraph
  {figures/count-cas-solver.csv}
  {south east}
  {\CHANGE{Valid} counter solver graph.}
  {\CHANGE{Valid} counter solving times in seconds for increasing values of $m$ and $n$.}
  {fig:count:cas:solver}
